{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1d5028-8a84-4b63-94ab-d1af23283fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import utils\n",
    "import sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11cc44bf-e81e-4e4f-b927-5125fc3949aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19c9310-f98c-442d-aecf-af3322e8a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_HOME = os.path.join('data', 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c935e54f-dcfb-435e-bdce-7891e8df42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(*src_filenames, labels=None):\n",
    "    data = []\n",
    "    for filename in src_filenames:\n",
    "        with open(filename) as f:\n",
    "            for line in f:\n",
    "                d = json.loads(line)\n",
    "                if labels is None or d['gold_label'] in labels:\n",
    "                    data.append(d)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e82fd73-49e9-416b-8bcc-d5f8e1511347",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynasent = load_dataset('data/sentiment/dynasent-v1.1/dynasent-v1.1-round01-yelp-train.jsonl')\n",
    "dynasent_2 = load_dataset('data/sentiment/dynasent-v1.1/dynasent-v1.1-round01-yelp-train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e2df880-95c4-4e40-ad62-2d3bd925f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roto-Rooter is always good when you need someo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's so worth the price of cox service over he...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I placed my order of \"sticky ribs\" as an appet...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is mandatory valet parking, so make sure...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>My wife and I couldn't finish it.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94453</th>\n",
       "      <td>Not to mention they killed Discount Tires prices.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94454</th>\n",
       "      <td>I have never been cussed out and told someone ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94456</th>\n",
       "      <td>From September 2010 visit:\\n\\nDecided to dine ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94457</th>\n",
       "      <td>Even fast food restaraunts deserve to be revie...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94458</th>\n",
       "      <td>I am so sorry the hear that this Pharmacy is c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80461 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence     label\n",
       "0      Roto-Rooter is always good when you need someo...  positive\n",
       "1      It's so worth the price of cox service over he...  positive\n",
       "2      I placed my order of \"sticky ribs\" as an appet...   neutral\n",
       "3      There is mandatory valet parking, so make sure...   neutral\n",
       "5                      My wife and I couldn't finish it.   neutral\n",
       "...                                                  ...       ...\n",
       "94453  Not to mention they killed Discount Tires prices.   neutral\n",
       "94454  I have never been cussed out and told someone ...  negative\n",
       "94456  From September 2010 visit:\\n\\nDecided to dine ...   neutral\n",
       "94457  Even fast food restaraunts deserve to be revie...   neutral\n",
       "94458  I am so sorry the hear that this Pharmacy is c...  negative\n",
       "\n",
       "[80461 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyna_df = pd.DataFrame(dynasent)[['sentence', 'gold_label']].dropna()\n",
    "dyna_df.columns = ['sentence', 'label']\n",
    "dyna_ = dyna_df[(dyna_df['label']!='mixed') & (dyna_df['sentence'].str.len()<400)]\n",
    "dyna_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c227707-6cde-4c7c-9fd7-1e670671764a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roto-Rooter is always good when you need someo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's so worth the price of cox service over he...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I placed my order of \"sticky ribs\" as an appet...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is mandatory valet parking, so make sure...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>My wife and I couldn't finish it.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94453</th>\n",
       "      <td>Not to mention they killed Discount Tires prices.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94454</th>\n",
       "      <td>I have never been cussed out and told someone ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94456</th>\n",
       "      <td>From September 2010 visit:\\n\\nDecided to dine ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94457</th>\n",
       "      <td>Even fast food restaraunts deserve to be revie...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94458</th>\n",
       "      <td>I am so sorry the hear that this Pharmacy is c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80461 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence     label\n",
       "0      Roto-Rooter is always good when you need someo...  positive\n",
       "1      It's so worth the price of cox service over he...  positive\n",
       "2      I placed my order of \"sticky ribs\" as an appet...   neutral\n",
       "3      There is mandatory valet parking, so make sure...   neutral\n",
       "5                      My wife and I couldn't finish it.   neutral\n",
       "...                                                  ...       ...\n",
       "94453  Not to mention they killed Discount Tires prices.   neutral\n",
       "94454  I have never been cussed out and told someone ...  negative\n",
       "94456  From September 2010 visit:\\n\\nDecided to dine ...   neutral\n",
       "94457  Even fast food restaraunts deserve to be revie...   neutral\n",
       "94458  I am so sorry the hear that this Pharmacy is c...  negative\n",
       "\n",
       "[80461 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyna2_df = pd.DataFrame(dynasent_2)[['sentence', 'gold_label']].dropna()\n",
    "dyna2_df.columns = ['sentence', 'label']\n",
    "dyna2_ = dyna2_df[(dyna2_df['label']!='mixed') & (dyna2_df['sentence'].str.len()<400)]\n",
    "dyna2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f739d56-068a-47a4-a803-e8b391c97793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>is_subtree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001-00001</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>00002-00001</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>00003-00001</td>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>00004-00001</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>00005-00001</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318453</th>\n",
       "      <td>08540-00001</td>\n",
       "      <td>A real snooze .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318460</th>\n",
       "      <td>08541-00001</td>\n",
       "      <td>No surprises .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318465</th>\n",
       "      <td>08542-00001</td>\n",
       "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318510</th>\n",
       "      <td>08543-00001</td>\n",
       "      <td>Her fans walked out muttering words like `` ho...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318573</th>\n",
       "      <td>08544-00001</td>\n",
       "      <td>In this case zero .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8544 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         example_id                                           sentence  \\\n",
       "0       00001-00001  The Rock is destined to be the 21st Century 's...   \n",
       "71      00002-00001  The gorgeously elaborate continuation of `` Th...   \n",
       "144     00003-00001  Singer\\/composer Bryan Adams contributes a sle...   \n",
       "221     00004-00001  You 'd think by now America would have had eno...   \n",
       "258     00005-00001               Yet the act is still charming here .   \n",
       "...             ...                                                ...   \n",
       "318453  08540-00001                                    A real snooze .   \n",
       "318460  08541-00001                                     No surprises .   \n",
       "318465  08542-00001  We 've seen the hippie-turned-yuppie plot befo...   \n",
       "318510  08543-00001  Her fans walked out muttering words like `` ho...   \n",
       "318573  08544-00001                                In this case zero .   \n",
       "\n",
       "           label  is_subtree  \n",
       "0       positive           0  \n",
       "71      positive           0  \n",
       "144     positive           0  \n",
       "221      neutral           0  \n",
       "258     positive           0  \n",
       "...          ...         ...  \n",
       "318453  negative           0  \n",
       "318460  negative           0  \n",
       "318465  positive           0  \n",
       "318510  negative           0  \n",
       "318573  negative           0  \n",
       "\n",
       "[8544 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = sst.train_reader(SST_HOME, include_subtrees=False)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a565bb1-58ca-4eeb-8814-a6cdbd37fbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_subtree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>3310</td>\n",
       "      <td>3310</td>\n",
       "      <td>3310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1624</td>\n",
       "      <td>1624</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>3610</td>\n",
       "      <td>3610</td>\n",
       "      <td>3610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          example_id  sentence  is_subtree\n",
       "label                                     \n",
       "negative        3310      3310        3310\n",
       "neutral         1624      1624        1624\n",
       "positive        3610      3610        3610"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9892200-6f9f-47a5-91ca-7651ad9d3735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_subtree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1624</td>\n",
       "      <td>1624</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1624</td>\n",
       "      <td>1624</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1624</td>\n",
       "      <td>1624</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          example_id  sentence  is_subtree\n",
       "label                                     \n",
       "negative        1624      1624        1624\n",
       "neutral         1624      1624        1624\n",
       "positive        1624      1624        1624"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ids = np.concatenate([np.where(movies['label']=='neutral')[0], \n",
    "                        np.where(movies['label']=='negative')[0][np.random.choice(3310, replace=False, size=1624)],\n",
    "                        np.where(movies['label']=='positive')[0][np.random.choice(3610, replace=False, size=1624)]])\n",
    "movies.iloc[m_ids].groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e4999b-9989-4b56-bd6a-87ec0288d0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>is_subtree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08545-00001</td>\n",
       "      <td>It 's a lovely film with lovely performances b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08546-00001</td>\n",
       "      <td>No one goes unindicted here , which is probabl...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08547-00001</td>\n",
       "      <td>And if you 're not nearly moved to tears by a ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08548-00001</td>\n",
       "      <td>A warm , funny , engaging film .</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08549-00001</td>\n",
       "      <td>Uses sharp humor and insight into human nature...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>09641-00001</td>\n",
       "      <td>it seems to me the film is about the art of ri...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>09642-00001</td>\n",
       "      <td>It 's just disappointingly superficial -- a mo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>09643-00001</td>\n",
       "      <td>The title not only describes its main characte...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>09644-00001</td>\n",
       "      <td>Sometimes it feels as if it might have been ma...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>09645-00001</td>\n",
       "      <td>Schaeffer has to find some hook on which to ha...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1101 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       example_id                                           sentence  \\\n",
       "0     08545-00001  It 's a lovely film with lovely performances b...   \n",
       "1     08546-00001  No one goes unindicted here , which is probabl...   \n",
       "2     08547-00001  And if you 're not nearly moved to tears by a ...   \n",
       "3     08548-00001                   A warm , funny , engaging film .   \n",
       "4     08549-00001  Uses sharp humor and insight into human nature...   \n",
       "...           ...                                                ...   \n",
       "1096  09641-00001  it seems to me the film is about the art of ri...   \n",
       "1097  09642-00001  It 's just disappointingly superficial -- a mo...   \n",
       "1098  09643-00001  The title not only describes its main characte...   \n",
       "1099  09644-00001  Sometimes it feels as if it might have been ma...   \n",
       "1100  09645-00001  Schaeffer has to find some hook on which to ha...   \n",
       "\n",
       "         label  is_subtree  \n",
       "0     positive           0  \n",
       "1      neutral           0  \n",
       "2     positive           0  \n",
       "3     positive           0  \n",
       "4     positive           0  \n",
       "...        ...         ...  \n",
       "1096  negative           0  \n",
       "1097  negative           0  \n",
       "1098  negative           0  \n",
       "1099   neutral           0  \n",
       "1100  negative           0  \n",
       "\n",
       "[1101 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_dev = sst.dev_reader(SST_HOME)\n",
    "movies_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c0c283f-861c-4119-9b4a-02f2598e80d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_subtree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>428</td>\n",
       "      <td>428</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>444</td>\n",
       "      <td>444</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          example_id  sentence  is_subtree\n",
       "label                                     \n",
       "negative         428       428         428\n",
       "neutral          229       229         229\n",
       "positive         444       444         444"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_dev.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "499a31ef-b6d4-421c-b5a2-b419c678533b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_subtree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          example_id  sentence  is_subtree\n",
       "label                                     \n",
       "negative         229       229         229\n",
       "neutral          229       229         229\n",
       "positive         229       229         229"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_ids = np.concatenate([np.where(movies_dev['label']=='neutral')[0], \n",
    "                        np.where(movies_dev['label']=='negative')[0][np.random.choice(428, replace=False, size=229)],\n",
    "                        np.where(movies_dev['label']=='positive')[0][np.random.choice(444, replace=False, size=229)]])\n",
    "movies_dev.iloc[md_ids].groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "407e1c1a-66d8-4341-bd6d-853bb12841bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>is_subtree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The wine choices are good though.</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Food and service were outstanding!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I would need to be convinced to go there again.</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I made the reservation on my iPhone using the ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The same level of expertise went into the desc...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>2357</td>\n",
       "      <td>They had added extra tables and it was a bit c...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>2358</td>\n",
       "      <td>The casino was difficult to navigate.</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>2359</td>\n",
       "      <td>They turned the volume down later.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>2360</td>\n",
       "      <td>We find it still best to explore this wonderfu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>2361</td>\n",
       "      <td>My wife tried to eat it but realized she could...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2361 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      example_id                                           sentence     label  \\\n",
       "0              1                  The wine choices are good though.  positive   \n",
       "1              2                 Food and service were outstanding!  positive   \n",
       "2              3    I would need to be convinced to go there again.  negative   \n",
       "3              4  I made the reservation on my iPhone using the ...   neutral   \n",
       "4              5  The same level of expertise went into the desc...   neutral   \n",
       "...          ...                                                ...       ...   \n",
       "2356        2357  They had added extra tables and it was a bit c...  negative   \n",
       "2357        2358              The casino was difficult to navigate.  negative   \n",
       "2358        2359                 They turned the volume down later.   neutral   \n",
       "2359        2360  We find it still best to explore this wonderfu...  positive   \n",
       "2360        2361  My wife tried to eat it but realized she could...   neutral   \n",
       "\n",
       "      is_subtree  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "2356           0  \n",
       "2357           0  \n",
       "2358           0  \n",
       "2359           0  \n",
       "2360           0  \n",
       "\n",
       "[2361 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants = sst.bakeoff_dev_reader(SST_HOME)\n",
    "restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2095b038-ba5f-4295-a1b1-30ebc1ccba4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_subtree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1019</td>\n",
       "      <td>1019</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>777</td>\n",
       "      <td>777</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          example_id  sentence  is_subtree\n",
       "label                                     \n",
       "negative         565       565         565\n",
       "neutral         1019      1019        1019\n",
       "positive         777       777         777"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a31e34-2e80-455d-997d-10a13763b4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_subtree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          example_id  sentence  is_subtree\n",
       "label                                     \n",
       "negative         565       565         565\n",
       "neutral          565       565         565\n",
       "positive         565       565         565"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_ids = np.concatenate([np.where(restaurants['label']=='negative')[0], \n",
    "                        np.where(restaurants['label']=='neutral')[0][np.random.choice(1019, replace=False, size=565)],\n",
    "                        np.where(restaurants['label']=='positive')[0][np.random.choice(777, replace=False, size=565)]])\n",
    "restaurants.iloc[r_ids].groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e152c27f-6d2c-44d3-91ee-1e23fff254e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bakeoff_test = sst.bakeoff_test_reader(SST_HOME)\n",
    "sst_test = sst.test_reader(SST_HOME)\n",
    "bakeoff_test['dataset'] = 'bakeoff'\n",
    "sst_test['dataset'] = 'sst3'\n",
    "df_test = pd.concat((bakeoff_test, sst_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "794188c2-6d44-4afe-892d-f9ff198cfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rtest = 1000\n",
    "n_dtrain = 5000\n",
    "n_dtest = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfdcad-b0b8-485e-b25c-344efe7a4990",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "f8719685-72cc-4253-995d-59a13ea00e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "b1c691b4-409b-4b56-adb0-885a0c55c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "7f34ec24-ed89-44cf-8ac7-defe095ffc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_emb = model.encode(df_test['sentence'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bcbb42ed-713c-4506-a58a-102c13035579",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_emb = model.encode(movies['sentence'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d610c6a7-02be-464a-b58b-9a30c3eabcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dev_emb = model.encode(movies_dev['sentence'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3f726ef0-82a9-4374-ac35-785a5f0fbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_emb = model.encode(restaurants['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fe25c3f6-4c91-44fb-a776-eeb09a62a887",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [145], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dyna_emb \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(dyna_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: output_tokens, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:553\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    552\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 553\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    562\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:340\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    338\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 340\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:299\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    292\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    298\u001b[0m ):\n\u001b[0;32m--> 299\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    307\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:240\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    233\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    239\u001b[0m ):\n\u001b[0;32m--> 240\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(self_outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m hidden_states)\n\u001b[1;32m    248\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dyna_emb = model.encode(dyna_df['sentence'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c05525e-d30c-42fe-a4fa-4a3a137e2d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch_rnn_classifier import TorchRNNModel\n",
    "from torch_deep_neural_classifier import ActivationLayer, TorchDeepNeuralClassifier\n",
    "from torch_shallow_neural_classifier import TorchShallowNeuralClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d0f2af7-702a-4940-8d96-f0bc19201bb3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TorchFunnelClassifier(TorchShallowNeuralClassifier):\n",
    "    def __init__(self,\n",
    "           hidden_dims=[50],\n",
    "            **base_kwargs):\n",
    "        \"\"\"\n",
    "        A dense, feed-forward network with the number of hidden layers\n",
    "        set by `num_layers`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_layers : int\n",
    "            Number of hidden layers in the network.\n",
    "\n",
    "        **base_kwargs\n",
    "            For details, see `torch_model_base.py`.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        loss: nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "        self.params: list\n",
    "            Extends TorchModelBase.params with names for all of the\n",
    "            arguments for this class to support tuning of these values\n",
    "            using `sklearn.model_selection` tools.\n",
    "\n",
    "        \"\"\"\n",
    "        self.num_layers = len(hidden_dims)\n",
    "        self.hidden_dims = hidden_dims\n",
    "        super().__init__(**base_kwargs)\n",
    "        self.loss = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "        self.params += ['num_layers']\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"\n",
    "        Define the model's computation graph.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        nn.Module\n",
    "\n",
    "        \"\"\"\n",
    "        # Input to hidden:\n",
    "        self.layers = [\n",
    "            ActivationLayer(\n",
    "                self.input_dim, self.hidden_dims[0], self.device, self.hidden_activation)]\n",
    "        # Hidden to hidden:\n",
    "        for i in range(self.num_layers-1):\n",
    "            self.layers += [\n",
    "                ActivationLayer(\n",
    "                    self.hidden_dims[i], self.hidden_dims[i+1], self.device, self.hidden_activation)]\n",
    "        # Hidden to output:\n",
    "        self.layers.append(\n",
    "            nn.Linear(self.hidden_dims[-1], self.n_classes_, device=self.device))\n",
    "        return nn.Sequential(*self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ccf450c-9d29-4b32-8578-cb7c70bf0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump([movies_emb, movies_dev_emb, restaurant_emb, dyna_emb], open('all-mpnet-base-v2_embeddings.p', 'bw'))\n",
    "file = 'data/sentiment/all-mpnet-base-v2_embeddings.p' # 'all-MiniLM-L12-v2_embeddings.p' # 'all-distilroberta-v1_embeddings.p' \n",
    "movies_emb, movies_dev_emb, restaurant_emb, dyna_emb, dyna2_emb = pickle.load(open(file, 'br'))   #, dyna_emb, dyna2_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b23c4462-5d43-4605-84fd-200dad7c1d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11233, 768), (11233,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_train_emb, restaurant_dev_emb = restaurant_emb[:-n_rtest], restaurant_emb[-n_rtest:]\n",
    "train_emb = np.concatenate([movies_emb[m_ids, :], \n",
    "                            restaurant_emb[:-n_rtest], \n",
    "                            dyna_emb[(dyna_df['label']!='mixed') & (dyna_df['sentence'].str.len()<400)][:n_dtrain, :] \n",
    "                            ], axis=0)\n",
    "labels = np.concatenate([movies['label'].values[m_ids], \n",
    "                         restaurants['label'].values[:-n_rtest], \n",
    "                         dyna_['label'].values[:n_dtrain]\n",
    "                        ])\n",
    "train_emb.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa1adb0d-229a-4800-96f8-f570a59ff67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =  TorchFunnelClassifier(hidden_dim=[12], max_iter=10000, \n",
    "                             eta=1e-3, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1772b267-545c-431e-a8aa-682e95904546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 2506. Training loss did not improve more than tol=1e-05. Final error is 0.0011282528430456296."
     ]
    },
    {
     "data": {
      "text/plain": [
       "TorchFunnelClassifier(\n",
       "\tbatch_size=1028,\n",
       "\tmax_iter=10000,\n",
       "\teta=0.001,\n",
       "\toptimizer_class=<class 'torch.optim.adam.Adam'>,\n",
       "\tl2_strength=0,\n",
       "\tgradient_accumulation_steps=1,\n",
       "\tmax_grad_norm=None,\n",
       "\tvalidation_fraction=0.1,\n",
       "\tearly_stopping=False,\n",
       "\tn_iter_no_change=10,\n",
       "\twarm_start=True,\n",
       "\ttol=1e-05,\n",
       "\thidden_dim=[12],\n",
       "\thidden_activation=Tanh(),\n",
       "\tnum_layers=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_emb, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "822eb2ca-8bf4-4551-9d5d-ebcacc71f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_predict = clf.predict(restaurant_emb[-n_rtest:])\n",
    "d_predict = clf.predict(dyna_emb[(dyna_df['label']!='mixed') & (dyna_df['sentence'].str.len()<400)][-n_dtest:])\n",
    "t_predict = clf.predict(train_emb)\n",
    "m_d_predict = clf.predict(movies_dev_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "2ed45307-6ce1-406c-8b59-dc68c3308d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['prediction'] = clf.predict(test_emb)\n",
    "# df_test.to_csv('cs224u-sentiment-bakeoff-entry.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7aacf05-e894-4cc1-8ee2-70a86867fdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xb/ksf3f8q50ws41h95k4th7z4w0000gp/T/ipykernel_55964/3777367176.py:3: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  f1s, np.mean(f1s), f1_score(labels, t_predict, average='macro'), f1_score(dyna_['label'][-n_dtest:], d_predict, average='macro')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6695434824320284, 0.5925900270612249],\n",
       " 0.6310667547466267,\n",
       " 1.0,\n",
       " 0.5877310853821287)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1s = [f1_score(restaurants['label'][-n_rtest:], r_predict, average='macro'), \n",
    "       f1_score(movies_dev['label'], m_d_predict, average='macro')]\n",
    "f1s, np.mean(f1s), f1_score(labels, t_predict, average='macro'), f1_score(dyna_['label'][-n_dtest:], d_predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "242e0d56-e7e7-45c0-afed-ae4ce7d51819",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(restaurants['label'][-n_rtest:], r_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3caf402d-2389-4eff-819e-bcce9c096af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x166fbe430>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d322a0-04c1-4d58-b2bc-808eacae3344",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RNN with Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef87a27d-8aba-4ea6-8ebb-d91b2be7eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_rnn_classifier import TorchRNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80e029f1-cc0e-4640-9776-2b6da57d5ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"data/glove.840B.300d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = ''.join(values[:-300])\n",
    "        vector = np.asarray(values[-300:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbcd2935-1a0a-4b44-8bed-0b72dee6d8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.082752</td>\n",
       "      <td>0.672040</td>\n",
       "      <td>-0.14987</td>\n",
       "      <td>-0.064983</td>\n",
       "      <td>0.056491</td>\n",
       "      <td>0.402280</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>-0.331100</td>\n",
       "      <td>-0.306910</td>\n",
       "      <td>2.0817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14331</td>\n",
       "      <td>0.018267</td>\n",
       "      <td>-0.18643</td>\n",
       "      <td>0.207090</td>\n",
       "      <td>-0.355980</td>\n",
       "      <td>0.053380</td>\n",
       "      <td>-0.050821</td>\n",
       "      <td>-0.191800</td>\n",
       "      <td>-0.378460</td>\n",
       "      <td>-0.06589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.207510</td>\n",
       "      <td>-0.12578</td>\n",
       "      <td>-0.593250</td>\n",
       "      <td>0.125250</td>\n",
       "      <td>0.159750</td>\n",
       "      <td>0.137480</td>\n",
       "      <td>-0.331570</td>\n",
       "      <td>-0.136940</td>\n",
       "      <td>1.7893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16165</td>\n",
       "      <td>-0.066737</td>\n",
       "      <td>-0.29556</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.281350</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.140190</td>\n",
       "      <td>0.138710</td>\n",
       "      <td>-0.360490</td>\n",
       "      <td>-0.03500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.272040</td>\n",
       "      <td>-0.062030</td>\n",
       "      <td>-0.18840</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>-0.018158</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>-0.138770</td>\n",
       "      <td>0.177080</td>\n",
       "      <td>0.177090</td>\n",
       "      <td>2.5882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42810</td>\n",
       "      <td>0.168990</td>\n",
       "      <td>0.22511</td>\n",
       "      <td>-0.285570</td>\n",
       "      <td>-0.102800</td>\n",
       "      <td>-0.018168</td>\n",
       "      <td>0.114070</td>\n",
       "      <td>0.130150</td>\n",
       "      <td>-0.183170</td>\n",
       "      <td>0.13230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-0.185670</td>\n",
       "      <td>0.066008</td>\n",
       "      <td>-0.25209</td>\n",
       "      <td>-0.117250</td>\n",
       "      <td>0.265130</td>\n",
       "      <td>0.064908</td>\n",
       "      <td>0.122910</td>\n",
       "      <td>-0.093979</td>\n",
       "      <td>0.024321</td>\n",
       "      <td>2.4926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59396</td>\n",
       "      <td>-0.097729</td>\n",
       "      <td>0.20072</td>\n",
       "      <td>0.170550</td>\n",
       "      <td>-0.004736</td>\n",
       "      <td>-0.039709</td>\n",
       "      <td>0.324980</td>\n",
       "      <td>-0.023452</td>\n",
       "      <td>0.123020</td>\n",
       "      <td>0.33120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.319240</td>\n",
       "      <td>0.063160</td>\n",
       "      <td>-0.27858</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>-0.214620</td>\n",
       "      <td>-0.104950</td>\n",
       "      <td>0.154950</td>\n",
       "      <td>-0.033530</td>\n",
       "      <td>2.4834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12977</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.18888</td>\n",
       "      <td>-0.004274</td>\n",
       "      <td>-0.106450</td>\n",
       "      <td>-0.258100</td>\n",
       "      <td>-0.044629</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>0.097801</td>\n",
       "      <td>0.25045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1        2         3         4         5         6    \\\n",
       ",   -0.082752  0.672040 -0.14987 -0.064983  0.056491  0.402280  0.002775   \n",
       ".    0.012001  0.207510 -0.12578 -0.593250  0.125250  0.159750  0.137480   \n",
       "the  0.272040 -0.062030 -0.18840  0.023225 -0.018158  0.006719 -0.138770   \n",
       "and -0.185670  0.066008 -0.25209 -0.117250  0.265130  0.064908  0.122910   \n",
       "to   0.319240  0.063160 -0.27858  0.261200  0.079248 -0.214620 -0.104950   \n",
       "\n",
       "          7         8       9    ...      290       291      292       293  \\\n",
       ",   -0.331100 -0.306910  2.0817  ... -0.14331  0.018267 -0.18643  0.207090   \n",
       ".   -0.331570 -0.136940  1.7893  ...  0.16165 -0.066737 -0.29556  0.022612   \n",
       "the  0.177080  0.177090  2.5882  ... -0.42810  0.168990  0.22511 -0.285570   \n",
       "and -0.093979  0.024321  2.4926  ... -0.59396 -0.097729  0.20072  0.170550   \n",
       "to   0.154950 -0.033530  2.4834  ... -0.12977  0.371300  0.18888 -0.004274   \n",
       "\n",
       "          294       295       296       297       298      299  \n",
       ",   -0.355980  0.053380 -0.050821 -0.191800 -0.378460 -0.06589  \n",
       ".   -0.281350  0.063500  0.140190  0.138710 -0.360490 -0.03500  \n",
       "the -0.102800 -0.018168  0.114070  0.130150 -0.183170  0.13230  \n",
       "and -0.004736 -0.039709  0.324980 -0.023452  0.123020  0.33120  \n",
       "to  -0.106450 -0.258100 -0.044629  0.082745  0.097801  0.25045  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_df = pd.DataFrame(embeddings_dict).transpose()\n",
    "glove_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "810f8424-fa77-444b-b346-0e8ad33c25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_df.to_hdf('glove.840B.300d.hdf', key='emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3cf1590-f814-4ec1-8286-736fc0222656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xb/ksf3f8q50ws41h95k4th7z4w0000gp/T/ipykernel_43298/706370959.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  glove_ = glove_df.append(pd.Series(glove_df.loc['<unk>'], name='$UNK'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.082752</td>\n",
       "      <td>0.672040</td>\n",
       "      <td>-0.14987</td>\n",
       "      <td>-0.064983</td>\n",
       "      <td>0.056491</td>\n",
       "      <td>0.402280</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>-0.331100</td>\n",
       "      <td>-0.306910</td>\n",
       "      <td>2.0817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14331</td>\n",
       "      <td>0.018267</td>\n",
       "      <td>-0.18643</td>\n",
       "      <td>0.207090</td>\n",
       "      <td>-0.355980</td>\n",
       "      <td>0.053380</td>\n",
       "      <td>-0.050821</td>\n",
       "      <td>-0.191800</td>\n",
       "      <td>-0.378460</td>\n",
       "      <td>-0.06589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.207510</td>\n",
       "      <td>-0.12578</td>\n",
       "      <td>-0.593250</td>\n",
       "      <td>0.125250</td>\n",
       "      <td>0.159750</td>\n",
       "      <td>0.137480</td>\n",
       "      <td>-0.331570</td>\n",
       "      <td>-0.136940</td>\n",
       "      <td>1.7893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16165</td>\n",
       "      <td>-0.066737</td>\n",
       "      <td>-0.29556</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.281350</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.140190</td>\n",
       "      <td>0.138710</td>\n",
       "      <td>-0.360490</td>\n",
       "      <td>-0.03500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.272040</td>\n",
       "      <td>-0.062030</td>\n",
       "      <td>-0.18840</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>-0.018158</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>-0.138770</td>\n",
       "      <td>0.177080</td>\n",
       "      <td>0.177090</td>\n",
       "      <td>2.5882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42810</td>\n",
       "      <td>0.168990</td>\n",
       "      <td>0.22511</td>\n",
       "      <td>-0.285570</td>\n",
       "      <td>-0.102800</td>\n",
       "      <td>-0.018168</td>\n",
       "      <td>0.114070</td>\n",
       "      <td>0.130150</td>\n",
       "      <td>-0.183170</td>\n",
       "      <td>0.13230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-0.185670</td>\n",
       "      <td>0.066008</td>\n",
       "      <td>-0.25209</td>\n",
       "      <td>-0.117250</td>\n",
       "      <td>0.265130</td>\n",
       "      <td>0.064908</td>\n",
       "      <td>0.122910</td>\n",
       "      <td>-0.093979</td>\n",
       "      <td>0.024321</td>\n",
       "      <td>2.4926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59396</td>\n",
       "      <td>-0.097729</td>\n",
       "      <td>0.20072</td>\n",
       "      <td>0.170550</td>\n",
       "      <td>-0.004736</td>\n",
       "      <td>-0.039709</td>\n",
       "      <td>0.324980</td>\n",
       "      <td>-0.023452</td>\n",
       "      <td>0.123020</td>\n",
       "      <td>0.33120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.319240</td>\n",
       "      <td>0.063160</td>\n",
       "      <td>-0.27858</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>-0.214620</td>\n",
       "      <td>-0.104950</td>\n",
       "      <td>0.154950</td>\n",
       "      <td>-0.033530</td>\n",
       "      <td>2.4834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12977</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.18888</td>\n",
       "      <td>-0.004274</td>\n",
       "      <td>-0.106450</td>\n",
       "      <td>-0.258100</td>\n",
       "      <td>-0.044629</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>0.097801</td>\n",
       "      <td>0.25045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z/28</th>\n",
       "      <td>0.734400</td>\n",
       "      <td>-0.336410</td>\n",
       "      <td>0.26918</td>\n",
       "      <td>0.418430</td>\n",
       "      <td>-0.189000</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.238750</td>\n",
       "      <td>-0.128790</td>\n",
       "      <td>-0.157970</td>\n",
       "      <td>-1.2841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.31101</td>\n",
       "      <td>-0.989550</td>\n",
       "      <td>0.27627</td>\n",
       "      <td>0.252650</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>-0.484320</td>\n",
       "      <td>-1.005500</td>\n",
       "      <td>0.637180</td>\n",
       "      <td>-0.139140</td>\n",
       "      <td>-0.16472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipout</th>\n",
       "      <td>0.212150</td>\n",
       "      <td>-0.994560</td>\n",
       "      <td>1.17820</td>\n",
       "      <td>2.072100</td>\n",
       "      <td>-0.442710</td>\n",
       "      <td>0.587300</td>\n",
       "      <td>0.261280</td>\n",
       "      <td>-0.425540</td>\n",
       "      <td>0.030910</td>\n",
       "      <td>-1.6743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19946</td>\n",
       "      <td>-0.198480</td>\n",
       "      <td>1.09150</td>\n",
       "      <td>-0.351070</td>\n",
       "      <td>-1.047200</td>\n",
       "      <td>-0.413820</td>\n",
       "      <td>-0.211390</td>\n",
       "      <td>0.934270</td>\n",
       "      <td>-0.932860</td>\n",
       "      <td>-0.51479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zulchzulu</th>\n",
       "      <td>-0.079690</td>\n",
       "      <td>-0.229050</td>\n",
       "      <td>0.80366</td>\n",
       "      <td>-0.788650</td>\n",
       "      <td>-0.405670</td>\n",
       "      <td>-0.157160</td>\n",
       "      <td>-0.423020</td>\n",
       "      <td>0.640810</td>\n",
       "      <td>-0.132150</td>\n",
       "      <td>-1.4109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64657</td>\n",
       "      <td>-0.415910</td>\n",
       "      <td>0.14240</td>\n",
       "      <td>-0.051749</td>\n",
       "      <td>0.389250</td>\n",
       "      <td>-0.205220</td>\n",
       "      <td>0.268780</td>\n",
       "      <td>-0.083561</td>\n",
       "      <td>0.485320</td>\n",
       "      <td>-0.73130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;unk&gt;</th>\n",
       "      <td>-0.079690</td>\n",
       "      <td>-0.229050</td>\n",
       "      <td>0.80366</td>\n",
       "      <td>-0.788650</td>\n",
       "      <td>-0.405670</td>\n",
       "      <td>-0.157160</td>\n",
       "      <td>-0.423020</td>\n",
       "      <td>0.640810</td>\n",
       "      <td>-0.132150</td>\n",
       "      <td>-1.4109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64657</td>\n",
       "      <td>-0.415910</td>\n",
       "      <td>0.14240</td>\n",
       "      <td>-0.051749</td>\n",
       "      <td>0.389250</td>\n",
       "      <td>-0.205220</td>\n",
       "      <td>0.268780</td>\n",
       "      <td>-0.083561</td>\n",
       "      <td>0.485320</td>\n",
       "      <td>-0.73130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$UNK</th>\n",
       "      <td>-0.079690</td>\n",
       "      <td>-0.229050</td>\n",
       "      <td>0.80366</td>\n",
       "      <td>-0.788650</td>\n",
       "      <td>-0.405670</td>\n",
       "      <td>-0.157160</td>\n",
       "      <td>-0.423020</td>\n",
       "      <td>0.640810</td>\n",
       "      <td>-0.132150</td>\n",
       "      <td>-1.4109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64657</td>\n",
       "      <td>-0.415910</td>\n",
       "      <td>0.14240</td>\n",
       "      <td>-0.051749</td>\n",
       "      <td>0.389250</td>\n",
       "      <td>-0.205220</td>\n",
       "      <td>0.268780</td>\n",
       "      <td>-0.083561</td>\n",
       "      <td>0.485320</td>\n",
       "      <td>-0.73130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2195894 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1        2         3         4         5    \\\n",
       ",         -0.082752  0.672040 -0.14987 -0.064983  0.056491  0.402280   \n",
       ".          0.012001  0.207510 -0.12578 -0.593250  0.125250  0.159750   \n",
       "the        0.272040 -0.062030 -0.18840  0.023225 -0.018158  0.006719   \n",
       "and       -0.185670  0.066008 -0.25209 -0.117250  0.265130  0.064908   \n",
       "to         0.319240  0.063160 -0.27858  0.261200  0.079248 -0.214620   \n",
       "...             ...       ...      ...       ...       ...       ...   \n",
       "z/28       0.734400 -0.336410  0.26918  0.418430 -0.189000  0.280200   \n",
       "zipout     0.212150 -0.994560  1.17820  2.072100 -0.442710  0.587300   \n",
       "zulchzulu -0.079690 -0.229050  0.80366 -0.788650 -0.405670 -0.157160   \n",
       "<unk>     -0.079690 -0.229050  0.80366 -0.788650 -0.405670 -0.157160   \n",
       "$UNK      -0.079690 -0.229050  0.80366 -0.788650 -0.405670 -0.157160   \n",
       "\n",
       "                6         7         8       9    ...      290       291  \\\n",
       ",          0.002775 -0.331100 -0.306910  2.0817  ... -0.14331  0.018267   \n",
       ".          0.137480 -0.331570 -0.136940  1.7893  ...  0.16165 -0.066737   \n",
       "the       -0.138770  0.177080  0.177090  2.5882  ... -0.42810  0.168990   \n",
       "and        0.122910 -0.093979  0.024321  2.4926  ... -0.59396 -0.097729   \n",
       "to        -0.104950  0.154950 -0.033530  2.4834  ... -0.12977  0.371300   \n",
       "...             ...       ...       ...     ...  ...      ...       ...   \n",
       "z/28       0.238750 -0.128790 -0.157970 -1.2841  ... -0.31101 -0.989550   \n",
       "zipout     0.261280 -0.425540  0.030910 -1.6743  ... -0.19946 -0.198480   \n",
       "zulchzulu -0.423020  0.640810 -0.132150 -1.4109  ...  0.64657 -0.415910   \n",
       "<unk>     -0.423020  0.640810 -0.132150 -1.4109  ...  0.64657 -0.415910   \n",
       "$UNK      -0.423020  0.640810 -0.132150 -1.4109  ...  0.64657 -0.415910   \n",
       "\n",
       "               292       293       294       295       296       297  \\\n",
       ",         -0.18643  0.207090 -0.355980  0.053380 -0.050821 -0.191800   \n",
       ".         -0.29556  0.022612 -0.281350  0.063500  0.140190  0.138710   \n",
       "the        0.22511 -0.285570 -0.102800 -0.018168  0.114070  0.130150   \n",
       "and        0.20072  0.170550 -0.004736 -0.039709  0.324980 -0.023452   \n",
       "to         0.18888 -0.004274 -0.106450 -0.258100 -0.044629  0.082745   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "z/28       0.27627  0.252650  0.479310 -0.484320 -1.005500  0.637180   \n",
       "zipout     1.09150 -0.351070 -1.047200 -0.413820 -0.211390  0.934270   \n",
       "zulchzulu  0.14240 -0.051749  0.389250 -0.205220  0.268780 -0.083561   \n",
       "<unk>      0.14240 -0.051749  0.389250 -0.205220  0.268780 -0.083561   \n",
       "$UNK       0.14240 -0.051749  0.389250 -0.205220  0.268780 -0.083561   \n",
       "\n",
       "                298      299  \n",
       ",         -0.378460 -0.06589  \n",
       ".         -0.360490 -0.03500  \n",
       "the       -0.183170  0.13230  \n",
       "and        0.123020  0.33120  \n",
       "to         0.097801  0.25045  \n",
       "...             ...      ...  \n",
       "z/28      -0.139140 -0.16472  \n",
       "zipout    -0.932860 -0.51479  \n",
       "zulchzulu  0.485320 -0.73130  \n",
       "<unk>      0.485320 -0.73130  \n",
       "$UNK       0.485320 -0.73130  \n",
       "\n",
       "[2195894 rows x 300 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_ = glove_df.append(pd.Series(glove_df.loc['<unk>'], name='$UNK'))\n",
    "glove_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "35750948-af13-4a0a-80c4-799a0936eb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8887"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = sst.build_dataset([movies, restaurants], rnn_phi, vectorize=False)\n",
    "mr_vocab = utils.get_vocab(d['X'], mincount=2)\n",
    "len(mr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5adeb70a-dc88-4c6d-87d7-422924888316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.597590</td>\n",
       "      <td>-0.640120</td>\n",
       "      <td>0.32797</td>\n",
       "      <td>-0.402370</td>\n",
       "      <td>-0.966060</td>\n",
       "      <td>0.059478</td>\n",
       "      <td>-0.215760</td>\n",
       "      <td>0.162160</td>\n",
       "      <td>-0.327970</td>\n",
       "      <td>-1.63230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259680</td>\n",
       "      <td>-0.331000</td>\n",
       "      <td>-0.600790</td>\n",
       "      <td>-0.491820</td>\n",
       "      <td>0.743190</td>\n",
       "      <td>-0.229990</td>\n",
       "      <td>-0.107790</td>\n",
       "      <td>-0.450780</td>\n",
       "      <td>-0.344750</td>\n",
       "      <td>-0.56342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>-0.075242</td>\n",
       "      <td>0.573370</td>\n",
       "      <td>-0.31908</td>\n",
       "      <td>-0.184840</td>\n",
       "      <td>0.888670</td>\n",
       "      <td>-0.273810</td>\n",
       "      <td>0.077588</td>\n",
       "      <td>0.139050</td>\n",
       "      <td>-0.477460</td>\n",
       "      <td>1.44420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035604</td>\n",
       "      <td>-0.022669</td>\n",
       "      <td>0.425310</td>\n",
       "      <td>0.063414</td>\n",
       "      <td>0.362130</td>\n",
       "      <td>-0.212800</td>\n",
       "      <td>-0.226150</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>-0.109340</td>\n",
       "      <td>-0.37948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.444670</td>\n",
       "      <td>0.695360</td>\n",
       "      <td>0.42748</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>0.117570</td>\n",
       "      <td>-0.213110</td>\n",
       "      <td>0.580860</td>\n",
       "      <td>0.073145</td>\n",
       "      <td>-0.085245</td>\n",
       "      <td>0.36655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281160</td>\n",
       "      <td>0.357600</td>\n",
       "      <td>-0.056253</td>\n",
       "      <td>0.219490</td>\n",
       "      <td>0.351250</td>\n",
       "      <td>-0.413770</td>\n",
       "      <td>-0.278680</td>\n",
       "      <td>-0.079391</td>\n",
       "      <td>-0.527170</td>\n",
       "      <td>-0.12413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>-0.607120</td>\n",
       "      <td>0.425440</td>\n",
       "      <td>0.51040</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>0.514750</td>\n",
       "      <td>0.082824</td>\n",
       "      <td>-0.415860</td>\n",
       "      <td>-0.343850</td>\n",
       "      <td>0.489610</td>\n",
       "      <td>0.70518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302490</td>\n",
       "      <td>-0.025315</td>\n",
       "      <td>0.471890</td>\n",
       "      <td>-0.226380</td>\n",
       "      <td>-0.974970</td>\n",
       "      <td>0.061226</td>\n",
       "      <td>-0.388950</td>\n",
       "      <td>-0.185880</td>\n",
       "      <td>0.025965</td>\n",
       "      <td>-0.48231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$UNK</th>\n",
       "      <td>-0.079690</td>\n",
       "      <td>-0.229050</td>\n",
       "      <td>0.80366</td>\n",
       "      <td>-0.788650</td>\n",
       "      <td>-0.405670</td>\n",
       "      <td>-0.157160</td>\n",
       "      <td>-0.423020</td>\n",
       "      <td>0.640810</td>\n",
       "      <td>-0.132150</td>\n",
       "      <td>-1.41090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646570</td>\n",
       "      <td>-0.415910</td>\n",
       "      <td>0.142400</td>\n",
       "      <td>-0.051749</td>\n",
       "      <td>0.389250</td>\n",
       "      <td>-0.205220</td>\n",
       "      <td>0.268780</td>\n",
       "      <td>-0.083561</td>\n",
       "      <td>0.485320</td>\n",
       "      <td>-0.73130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zings</th>\n",
       "      <td>-0.096697</td>\n",
       "      <td>-0.070718</td>\n",
       "      <td>0.10291</td>\n",
       "      <td>-0.438350</td>\n",
       "      <td>-0.008710</td>\n",
       "      <td>0.322620</td>\n",
       "      <td>0.421340</td>\n",
       "      <td>-0.069360</td>\n",
       "      <td>0.701790</td>\n",
       "      <td>-0.97765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267520</td>\n",
       "      <td>-0.160580</td>\n",
       "      <td>-0.214600</td>\n",
       "      <td>-0.342480</td>\n",
       "      <td>0.098743</td>\n",
       "      <td>-0.258170</td>\n",
       "      <td>-0.066133</td>\n",
       "      <td>-0.096388</td>\n",
       "      <td>-0.178550</td>\n",
       "      <td>0.16520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zippy</th>\n",
       "      <td>-0.119490</td>\n",
       "      <td>0.360940</td>\n",
       "      <td>0.01845</td>\n",
       "      <td>-0.013415</td>\n",
       "      <td>0.131960</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>0.131120</td>\n",
       "      <td>-0.258200</td>\n",
       "      <td>0.240580</td>\n",
       "      <td>-0.86782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249840</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.542730</td>\n",
       "      <td>-0.153530</td>\n",
       "      <td>0.424870</td>\n",
       "      <td>-0.241470</td>\n",
       "      <td>0.166220</td>\n",
       "      <td>-0.687120</td>\n",
       "      <td>-0.661260</td>\n",
       "      <td>-0.21029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>-0.148990</td>\n",
       "      <td>-0.872880</td>\n",
       "      <td>-0.22808</td>\n",
       "      <td>-0.508730</td>\n",
       "      <td>-0.003949</td>\n",
       "      <td>-0.188800</td>\n",
       "      <td>-0.356310</td>\n",
       "      <td>-0.148940</td>\n",
       "      <td>0.191140</td>\n",
       "      <td>1.18480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433680</td>\n",
       "      <td>-0.093496</td>\n",
       "      <td>-0.165160</td>\n",
       "      <td>0.552950</td>\n",
       "      <td>-0.138570</td>\n",
       "      <td>-0.158480</td>\n",
       "      <td>-0.589230</td>\n",
       "      <td>-0.066741</td>\n",
       "      <td>-0.383160</td>\n",
       "      <td>0.32494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0.270730</td>\n",
       "      <td>-0.087394</td>\n",
       "      <td>-0.36834</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>1.144800</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>0.553720</td>\n",
       "      <td>-0.094013</td>\n",
       "      <td>-0.552430</td>\n",
       "      <td>2.01740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506370</td>\n",
       "      <td>0.652430</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>-0.141300</td>\n",
       "      <td>0.378510</td>\n",
       "      <td>0.152990</td>\n",
       "      <td>-0.393860</td>\n",
       "      <td>0.036836</td>\n",
       "      <td>-0.217180</td>\n",
       "      <td>-0.34061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>~</th>\n",
       "      <td>-0.498400</td>\n",
       "      <td>0.547080</td>\n",
       "      <td>-0.14090</td>\n",
       "      <td>0.106580</td>\n",
       "      <td>0.378480</td>\n",
       "      <td>0.036685</td>\n",
       "      <td>0.019807</td>\n",
       "      <td>0.205680</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.14389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153780</td>\n",
       "      <td>0.158420</td>\n",
       "      <td>-0.230360</td>\n",
       "      <td>-0.152600</td>\n",
       "      <td>0.057458</td>\n",
       "      <td>-0.184350</td>\n",
       "      <td>0.127690</td>\n",
       "      <td>0.186070</td>\n",
       "      <td>-0.048666</td>\n",
       "      <td>0.46461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8887 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1        2         3         4         5         6    \\\n",
       "        0.597590 -0.640120  0.32797 -0.402370 -0.966060  0.059478 -0.215760   \n",
       "\"      -0.075242  0.573370 -0.31908 -0.184840  0.888670 -0.273810  0.077588   \n",
       "#      -0.444670  0.695360  0.42748  0.219060  0.117570 -0.213110  0.580860   \n",
       "$      -0.607120  0.425440  0.51040 -0.287500  0.514750  0.082824 -0.415860   \n",
       "$UNK   -0.079690 -0.229050  0.80366 -0.788650 -0.405670 -0.157160 -0.423020   \n",
       "...          ...       ...      ...       ...       ...       ...       ...   \n",
       "zings  -0.096697 -0.070718  0.10291 -0.438350 -0.008710  0.322620  0.421340   \n",
       "zippy  -0.119490  0.360940  0.01845 -0.013415  0.131960  0.572500  0.131120   \n",
       "zombie -0.148990 -0.872880 -0.22808 -0.508730 -0.003949 -0.188800 -0.356310   \n",
       "zone    0.270730 -0.087394 -0.36834 -0.000766  1.144800  0.020719  0.553720   \n",
       "~      -0.498400  0.547080 -0.14090  0.106580  0.378480  0.036685  0.019807   \n",
       "\n",
       "             7         8        9    ...       290       291       292  \\\n",
       "        0.162160 -0.327970 -1.63230  ...  0.259680 -0.331000 -0.600790   \n",
       "\"       0.139050 -0.477460  1.44420  ... -0.035604 -0.022669  0.425310   \n",
       "#       0.073145 -0.085245  0.36655  ...  0.281160  0.357600 -0.056253   \n",
       "$      -0.343850  0.489610  0.70518  ... -0.302490 -0.025315  0.471890   \n",
       "$UNK    0.640810 -0.132150 -1.41090  ...  0.646570 -0.415910  0.142400   \n",
       "...          ...       ...      ...  ...       ...       ...       ...   \n",
       "zings  -0.069360  0.701790 -0.97765  ...  0.267520 -0.160580 -0.214600   \n",
       "zippy  -0.258200  0.240580 -0.86782  ... -0.249840  0.354430  0.542730   \n",
       "zombie -0.148940  0.191140  1.18480  ... -0.433680 -0.093496 -0.165160   \n",
       "zone   -0.094013 -0.552430  2.01740  ...  0.506370  0.652430  0.301000   \n",
       "~       0.205680  0.233300  0.14389  ... -0.153780  0.158420 -0.230360   \n",
       "\n",
       "             293       294       295       296       297       298      299  \n",
       "       -0.491820  0.743190 -0.229990 -0.107790 -0.450780 -0.344750 -0.56342  \n",
       "\"       0.063414  0.362130 -0.212800 -0.226150  0.328000 -0.109340 -0.37948  \n",
       "#       0.219490  0.351250 -0.413770 -0.278680 -0.079391 -0.527170 -0.12413  \n",
       "$      -0.226380 -0.974970  0.061226 -0.388950 -0.185880  0.025965 -0.48231  \n",
       "$UNK   -0.051749  0.389250 -0.205220  0.268780 -0.083561  0.485320 -0.73130  \n",
       "...          ...       ...       ...       ...       ...       ...      ...  \n",
       "zings  -0.342480  0.098743 -0.258170 -0.066133 -0.096388 -0.178550  0.16520  \n",
       "zippy  -0.153530  0.424870 -0.241470  0.166220 -0.687120 -0.661260 -0.21029  \n",
       "zombie  0.552950 -0.138570 -0.158480 -0.589230 -0.066741 -0.383160  0.32494  \n",
       "zone   -0.141300  0.378510  0.152990 -0.393860  0.036836 -0.217180 -0.34061  \n",
       "~      -0.152600  0.057458 -0.184350  0.127690  0.186070 -0.048666  0.46461  \n",
       "\n",
       "[8887 rows x 300 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_.loc[mr_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "587d2800-e819-42f3-afca-f91f7c88db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e8969638-27a8-4fbc-a150-fdd679f8194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_phi(text):\n",
    "    drop = ['s&w', 'w/', '\"by', '$10', '$100', '$200', '$25', '$30', '$300', '$4', '$40', '$5', '$500', '$70', '$9', '20%', 'achronological', 'ahola', 'alagna', 'apted', 'assayas', 'attal', 'audiard', 'auteil', 'auteuil', 'berling', 'bielinsky', 'birot', 'bogdanovich', 'burstein', 'buñuel', 'byler', 'béart', 'c.h.o.', 'cacoyannis', 'cantet', 'chabrol', 'chaiken', 'chouraqui', 'clayburgh', 'cletis', 'clockstoppers', 'cockettes', 'collinwood', 'cuaron', 'decasia', 'egoyan', 'famuyiwa', 'feardotcom', 'fessenden', 'fresnadillo', 'gaghan', 'gayton', 'gheorghiu', 'goldbacher', 'hanussen', 'hashiguchi', 'hickenlooper', 'hitchcockian', 'holofcener', 'hudlin', 'idemoto', 'imamura', 'intacto', 'iwai', 'jacquot', 'jaglom', 'janklowicz', 'jarecki', 'juwanna', 'kieslowski', 'koepp', 'kosashvili', 'kosminsky', 'koury', 'kouyate', 'kurys', 'labute', 'lapaglia', 'maggiano', 'majidi', 'mattei', 'meyjes', 'morvern', 'muccino', 'musset', 'nachtwey', 'naipaul', 'nebrida', 'nettelbeck', 'nickleby', 'nijinsky', 'nohe', 'oedekerk', 'ozpetek', 'payami', 'pellington', 'peploe', 'rohmer', 'romanek', 'rubbo', 'ruggero', 'runteldat', 'schepisi', 'scherfig', 'schnitzler', 'seldahl', 'serrault', 'shadyac', 'shainberg', 'silberling', 'solondz', 'sonnenfeld', 'testud', 'twohy', 'tykwer', 'uncinematic', 'waydowntown', 'wertmuller', 'windtalkers', 'wollter', 'zhuangzhuang']\n",
    "    seq = re.split(', |_|-| |\\\\\\\\/|\\'|!|\\.|\\)|\\(|:|\\?|;', text.lower())\n",
    "    seq = [s for s in seq if s not in drop]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9322b84b-1b4f-4204-81a1-9a95f0c432a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rnn_classifier(X, y):\n",
    "    # sst_glove_vocab = utils.get_vocab(X, mincount=2)\n",
    "    mod = TorchRNNClassifier(\n",
    "        [],\n",
    "        early_stopping=True,\n",
    "        use_embedding=False)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c59b46df-3894-4d2f-9f1a-716fa634ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lara.thompson/code/cs224u/torch_rnn_classifier.py:379: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  new_X = [torch.FloatTensor(ex) for ex in X]\n",
      "Stopping after epoch 14. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 0.6584565043449402/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.000     0.000     0.000         4\n",
      "     neutral      0.000     0.000     0.000        13\n",
      "    positive      0.837     0.988     0.906        83\n",
      "\n",
      "    accuracy                          0.820       100\n",
      "   macro avg      0.279     0.329     0.302       100\n",
      "weighted avg      0.694     0.820     0.752       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_experiment = sst.experiment(\n",
    "    [movies, restaurants.iloc[:-n_rtest]],\n",
    "    rnn_phi,\n",
    "    fit_rnn_classifier,\n",
    "    vectorize=False,  # For deep learning, use `vectorize=False`.\n",
    "    assess_dataframes=[movies_dev, restaurants.iloc[-n_rtest]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6bd57-fb59-4030-9799-7b078431a62b",
   "metadata": {},
   "source": [
    "# RNN with Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb2117-c4a8-4b10-9aed-4e5e39d330a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get bert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6097c1c6-4875-4dff-8356-d9acd58896dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1ef86c46-95f0-41d9-a62c-ac219848cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0d4bf64d-c58a-48da-a78e-a02cdb051582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_weights_name = 'bert-base-cased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
    "bert_model = BertModel.from_pretrained(bert_weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4c00119e-6573-40f1-96ac-c4791a67815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_phi(text):\n",
    "    subtok_ids = vsm.hf_encode(text, bert_tokenizer)\n",
    "    torch_array = vsm.hf_represent(subtok_ids, bert_model, layer=-1)\n",
    "    return [torch_array[0, i, :].numpy() for i in range(torch_array.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3170989d-b4bd-499b-9a70-04e91d956df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Xy(df, phi):\n",
    "    X = df['sentence'].apply(phi).tolist()\n",
    "    y = df['label'].values\n",
    "    return {'X': X, 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b4e48b-bbd0-4cbc-952a-8e0f15afef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr_last, yr_last = build_Xy(restaurants, bert_phi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "33364ad2-1fe6-47a9-9f8a-8814e93b369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm_last, ym_last = build_Xy(movies, bert_phi) \n",
    "Xmd_last, ymd_last = build_Xy(movies_dev, bert_phi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "297cfaa2-fd25-4b91-b919-410ddb82df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sst.build_dataset(\n",
    "    movies,\n",
    "    bert_phi,\n",
    "    vectorizer=None,\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ef5e73c5-8d9f-4890-ab33-cbe371699f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_bert = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "546d7904-f213-4697-b224-ee6b9a3fcb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_bert = sst.build_dataset(\n",
    "    restaurants,\n",
    "    bert_phi,\n",
    "    vectorizer=None,\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3344e3d5-1e70-4cb5-a58f-8a9678d045ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "movd_bert = sst.build_dataset(\n",
    "    movies_dev,\n",
    "    bert_phi,\n",
    "    vectorizer=None,\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c23fe4c1-9fd8-4241-85a3-ac4328bea5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movt_bert = sst.build_dataset(\n",
    "    movies_test,\n",
    "    bert_phi,\n",
    "    vectorizer=None,\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f87e4-9ea0-41a0-8bdd-c6a74b9f8f6a",
   "metadata": {},
   "source": [
    "## or just load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "15885505-2b0e-4905-a155-43cb156660ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mov_bert, movd_bert, rest_bert = pickle.load(open('bert_lastlayer.p', 'br'))\n",
    "dyna2_bert = pickle.load(open('bert_lastlayer_dyna2.p', 'br')) #dyna_bert, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3e6f127a-0daf-42ce-bb59-b082d45973f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dyna2_bert['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24cffa6-db10-4bc5-8422-3d958b9a72f0",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7f752e48-be49-4eb4-960d-9a2eabfd812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [se for i, se in enumerate(mov_bert['X']) if i in m_ids] + [se for i, se in enumerate(rest_bert['X']) if i in r_ids[:-1000]] + [\n",
    "           se for i, se in enumerate(movd_bert['X']) if i in md_ids[:-500]]\n",
    "y_train = [l for i, l in enumerate(mov_bert['y']) if i in m_ids] + [l for i, l in enumerate(rest_bert['y']) if i in r_ids[:-1000]] + [\n",
    "           l for i, l in enumerate(movd_bert['y']) if i in md_ids[:-500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5b9cd248-2f83-4102-b31c-5584cf97678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [se for i, se in enumerate(rest_bert['X']) if i not in r_ids[:-1000]] + [\n",
    "    se for i, se in enumerate(movd_bert['X']) if i not in md_ids[:-500]]\n",
    "y_test = [l for i, l in enumerate(rest_bert['y']) if i not in r_ids[:-1000]] + [\n",
    "    l for i, l in enumerate(movd_bert['y']) if i not in md_ids[:-500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2b4e8697-2a0c-43a2-b212-4d314555c2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5754"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a9374096-eb39-430e-bb95-481980d612aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mov_bert['X'] + rest_bert['X'][:-n_rtest] + dyna2_bert['X'][:5000]\n",
    "y_train =  mov_bert['y'] + rest_bert['y'][:-n_rtest] + list(dyna2_bert['y'][:5000])\n",
    "\n",
    "X_test =  movd_bert['X'] + rest_bert['X'][-n_rtest:] + dyna2_bert['X'][5000:6000]\n",
    "y_test = movd_bert['y'] + rest_bert['y'][-n_rtest:] + list(dyna2_bert['y'][5000:6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "fc5dc288-2e00-4a12-85ae-918d643da991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 32. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 0.005834389041410759"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TorchRNNClassifier(\n",
       "\tbatch_size=1028,\n",
       "\tmax_iter=1000,\n",
       "\teta=0.001,\n",
       "\toptimizer_class=<class 'torch.optim.adam.Adam'>,\n",
       "\tl2_strength=0,\n",
       "\tgradient_accumulation_steps=1,\n",
       "\tmax_grad_norm=None,\n",
       "\tvalidation_fraction=0.1,\n",
       "\tearly_stopping=True,\n",
       "\tn_iter_no_change=10,\n",
       "\twarm_start=True,\n",
       "\ttol=1e-05,\n",
       "\thidden_dim=200,\n",
       "\tembed_dim=768,\n",
       "\tembedding=None,\n",
       "\tuse_embedding=False,\n",
       "\trnn_cell_class=<class 'torch.nn.modules.rnn.LSTM'>,\n",
       "\tbidirectional=True,\n",
       "\tfreeze_embedding=False,\n",
       "\tclassifier_activation=ReLU())"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = TorchRNNClassifier(\n",
    "    [],\n",
    "    early_stopping=True, warm_start=True,\n",
    "    hidden_dim=200, bidirectional=True,\n",
    "    use_embedding=False, \n",
    ")\n",
    "mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0d0c322b-319b-47aa-930a-f1b34ec4f41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.521338319448645"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_t = mod.predict(X_test)\n",
    "f1_score(y_test, predict_t, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b534c9ad-9f97-4f75-96dd-4b0acab31c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5497671188015758, 0.5898036234365646] 0.5697853711190701\n"
     ]
    }
   ],
   "source": [
    "f1s = [f1_score(y, mod.predict(X), average='macro') for y, X in [(movd_bert['y'], movd_bert['X']), \n",
    "                                                                 (rest_bert['y'][-n_rtest:], rest_bert['X'][-n_rtest:])]]\n",
    "print(f1s, np.mean(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "2f4b1a47-d1b6-4f25-9e7a-af9686acbc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1b0f94700>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predict_t)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=mod.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a380295-a562-4b79-b90b-641ffaf7043f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
