{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1b7c849-8856-41a5-8407-4e105631334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FlaxBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('pooler', 'dense', 'kernel'), ('pooler', 'dense', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import FlaxBertModel, BertTokenizerFast, BertConfig\n",
    "from datasets import load_dataset\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "config = BertConfig(model_name)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = FlaxBertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcea3c88-240e-448a-8149-05eb1d0fa513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(t, s=0):\n",
    "    if isinstance(t, dict):\n",
    "        for key in t:\n",
    "            print(\"\\t\"*s + str(key) + ':')\n",
    "            formatData(t[key], s+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f78e3e37-5e62-41a9-b5da-1fdb24eff981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.17.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": \"bert-base-uncased\"\n",
       "}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba7937e4-a3ff-4827-b255-2aaa8977a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "  \"attention_probs_dropout_prob\": 0.1,\n",
    "  \"classifier_dropout\": None,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_dropout_prob\": 0.1,\n",
    "  \"hidden_size\": 768,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"layer_norm_eps\": 1e-12,\n",
    "  \"max_position_embeddings\": 512,\n",
    "  \"model_type\": \"bert\",\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 12,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"position_embedding_type\": \"absolute\",\n",
    "  \"transformers_version\": \"4.17.0\",\n",
    "  \"type_vocab_size\": 2,\n",
    "  \"use_cache\": True,\n",
    "  \"vocab_size\": 30522\n",
    "}\n",
    "sm_config_dict = config_dict\n",
    "sm_config_dict[\"num_hidden_layers\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a20ae7d-e1a3-4064-b385-cc0d2eb17023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 2,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.17.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_config = BertConfig(**sm_config_dict)\n",
    "sm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a542cf37-dfdf-456c-bbf7-e863d0f14b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model = FlaxBertModel(sm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca73cef7-2ede-4e1e-8c31-2de7bf69a7d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings:\n",
      "\tLayerNorm:\n",
      "\t\tbias:\n",
      "\t\tscale:\n",
      "\tposition_embeddings:\n",
      "\t\tembedding:\n",
      "\ttoken_type_embeddings:\n",
      "\t\tembedding:\n",
      "\tword_embeddings:\n",
      "\t\tembedding:\n",
      "encoder:\n",
      "\tlayer:\n",
      "\t\t0:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t1:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t10:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t11:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t2:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t3:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t4:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t5:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t6:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t7:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t8:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t9:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "pooler:\n",
      "\tdense:\n",
      "\t\tkernel:\n",
      "\t\tbias:\n"
     ]
    }
   ],
   "source": [
    "formatData(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "585f193f-1f5f-453e-b8a6-f376d4666910",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings:\n",
      "\tLayerNorm:\n",
      "\t\tbias:\n",
      "\t\tscale:\n",
      "\tposition_embeddings:\n",
      "\t\tembedding:\n",
      "\ttoken_type_embeddings:\n",
      "\t\tembedding:\n",
      "\tword_embeddings:\n",
      "\t\tembedding:\n",
      "encoder:\n",
      "\tlayer:\n",
      "\t\t0:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t1:\n",
      "\t\t\tattention:\n",
      "\t\t\t\toutput:\n",
      "\t\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tscale:\n",
      "\t\t\t\t\tdense:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\tself:\n",
      "\t\t\t\t\tkey:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tquery:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\t\t\tvalue:\n",
      "\t\t\t\t\t\tbias:\n",
      "\t\t\t\t\t\tkernel:\n",
      "\t\t\tintermediate:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "\t\t\toutput:\n",
      "\t\t\t\tLayerNorm:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tscale:\n",
      "\t\t\t\tdense:\n",
      "\t\t\t\t\tbias:\n",
      "\t\t\t\t\tkernel:\n",
      "pooler:\n",
      "\tdense:\n",
      "\t\tbias:\n",
      "\t\tkernel:\n"
     ]
    }
   ],
   "source": [
    "formatData(sm_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4baa6add-28e8-4686-b361-e4afde83383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model.params['embeddings'] = model.params['embeddings']\n",
    "sm_model.params['pooler'] = model.params['pooler']\n",
    "for i in range(2):\n",
    "    sm_model.params['encoder']['layer'][str(i)] = model.params['encoder']['layer'][str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca6aaa-f335-418d-b380-5b19ae3eb4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "244d5a40-de58-4d4a-b3db-6b5fc5808bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset('oscar', \"unshuffled_deduplicated_en\", split='train', streaming=True)\n",
    "\n",
    "# dummy_input = next(iter(dataset))[\"text\"]\n",
    "\n",
    "dummy_input = \"The boulder has a steep burly start, then a delicate mantle finish.\"\n",
    "input_ids = tokenizer(dummy_input, return_tensors=\"np\").input_ids #[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ca95266-a3fc-4896-856b-c7019b3a58fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The boulder has a steep burly start, then a delicate mantle finish.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f9a3b10-0ae0-40a8-9a91-37eed94cdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a forward pass, should return an object `FlaxBaseModelOutputWithPooling`\n",
    "reps = model(input_ids, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45b7e136-61cc-4e19-a07f-c2775e88de7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d987054e-2e48-42e0-9bcc-4d2c15b43015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17, 768)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "081c2b88-ca0e-4b9f-85d2-d6f1feb3876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067cb9a-a25e-4a5f-aaa7-96388316f5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8f03478-a690-4d93-befa-1ee6afa1f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_inputs = [\"The boulder has a steep burly start, then a delicate mantle finish.\",\n",
    "                \"Sit start is pretty scrunchy -- harder for the very tall!\"]\n",
    "\n",
    "input_ids = tokenizer.batch_encode_plus(\n",
    "    dummy_inputs,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0330cb1-0d78-46cf-b2e8-19adf27a94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = model(jnp.array(input_ids['input_ids']), attention_mask=jnp.array(input_ids['attention_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d2d4772-c637-47c2-a418-1ddc4dc3ac01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53bab2ff-2468-4e0d-b858-f55b0135a225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 17, 768)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b72856-4ea5-4475-94c6-044d69113b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, \\\n",
    "    FlaxAutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa436098-4087-4ad5-8770-3f09a934a94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/file_utils.py\", line 2777, in _get_module\n",
      "  File \"/Users/lara.thompson/.pyenv/versions/3.9.13/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/models/mbart/configuration_mbart.py\", line 23, in <module>\n",
      "    from ...utils import TensorType, is_torch_available, logging\n",
      "ImportError: cannot import name 'TensorType' from 'transformers.utils' (/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/utils/__init__.py)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/xb/ksf3f8q50ws41h95k4th7z4w0000gp/T/ipykernel_11726/3887475848.py\", line 12, in <module>\n",
      "    model = FlaxAutoModelForSequenceClassification.from_pretrained(\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 445, in from_pretrained\n",
      "    **hub_kwargs,\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 576, in keys\n",
      "    class _LazyAutoMapping(OrderedDict):\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 577, in <listcomp>\n",
      "    \"\"\"\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 573, in _load_attr_from_module\n",
      "    raise ValueError(f\"Could not find {attr} in {transformers_module}!\")\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 535, in getattribute_from_module\n",
      "    from_pretrained_docstring = from_pretrained_docstring.replace(\"BaseAutoModelClass\", name)\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/file_utils.py\", line 2767, in __getattr__\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/file_utils.py\", line 2779, in _get_module\n",
      "RuntimeError: Failed to import transformers.models.mbart.configuration_mbart because of the following error (look up to see its traceback):\n",
      "cannot import name 'TensorType' from 'transformers.utils' (/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/transformers/utils/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/lara.thompson/.local/share/virtualenvs/lara.thompson-C83ZgnRu/lib/python3.9/site-packages/executing/executing.py\", line 167, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    finetuning_task='sst3',\n",
    "    use_auth_token=None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast=True,\n",
    "    use_auth_token=None,\n",
    ")\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "    use_auth_token=None,\n",
    "    # from_pt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e122a-a7aa-4fcd-861c-bbea62292ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
