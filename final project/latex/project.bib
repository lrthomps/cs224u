@Article{GGN4R2022,
  author="Shiwen Wu and Fei Sun and Wentao Zhang and Xu Xie and Bin Cui",
  title="Graph Neural Networks in Recommender Systems: A Survey",
  journal="ACM Comput. Surv.",
  volume="55",
  pages="1--37",
  number="5",
  year="2022",
  month="April",
  url="https://dl.acm.org/doi/10.1145/3535101"
}
@Article{Dor2018,
  author="Liat Ein Dor and Yosi Mass and Alon Halfon and Elad Venezian and others",
  title="Learning Thematic Similarity Metric from Article Sections Using Triplet Networks",
  journal="Proceedings of the 56th Annual Meeting of the As- sociation for Computational Linguistics",
  volume="2",
  pages="49--54",
  year="2018",
  note            = "\url{https://research.ibm.com/haifa/dept/vst/debating_data.shtml}",
}
@Article{Bowman2015,
  author="Samuel R. Bowman and Gabor Angeli and Christopher Potts and Christopher D. Manning",
  year="2015",
  title="A large anno-tated corpus for learning natural language inference",
  journal="Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing", 
  pages="632--642",
  note            = "\url{https://nlp.stanford.edu/projects/snli/}",
}
@article{Williams2018,
  author          = "Adina Williams and Nikita Nangia and Samuel Bowman",
  journal         = "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
  title           = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
  volume          = "1",
  year            = "2018",
  pages           = "1112--1122",
  note            = "\url{https://cims.nyu.edu/~sbowman/multinli/}", 
}
@article{Misra2016,
  author          = "Amita Misra and Brian Ecker and Marilyn A. Walker",
  journal         = "Proceedings of the SIGDIAL 2016 Conference, The 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
  title           = "Measuring the Similarity of Sentential Arguments in Dialogue",
  year            = "2016",
  pages           = "276--287",
  note            = "\url{https://nlds.soe.ucsc.edu/node/44}",
}
@article{Cer2017,
  author          = "Daniel Cer and Mona Diab and Eneko Agirre and Iigo Lopez-Gazpio and Lucia Specia",
  journal         = "Proceedings of the 11th International Workshop on Semantic Evaluation",
  title           = "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation",
  year            = "2017",
  pages           = "1--14",
  note            = "\url{https://github.com/brmson/dataset-sts}",
}
@article{Arora2017,
  author          = "Sanjeev Arora and Yingyu Liang and Tengyu Ma",
  journal         = "5th International Conference on Learning Representations, ICLR 2017",
  title           = "A Simple but Tough-to-Beat Baseline for Sentence Embeddings",
  year            = "2017",
  url             = "https://openreview.net/pdf?id=SyK00v5xx",
}
@inproceedings{Reimers2019,
  title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
  month = "11",
  year = "2019",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/1908.10084",
}
@inproceedings{Conneau2018,
  author          = "Alexis Conneau and Douwe Kiela",
  title           = "SentEval: An Evaluation Toolkit for Universal Sentence Representations",
  booktitle       = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)",
  month           = "5",
  year            = "2018",
  note            = "\url{https://github.com/facebookresearch/SentEval}",
  url             = "https://aclanthology.org/L18-1269/",
}
@inproceedings{ColBERT,
  author          = "Omar Khattab and Matei Zaharia",
  booktitle       = "SIGIR '20: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval",
  title           = "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
  month           = "July",
  year            = "2020",
  pages           = "39--48",
  url             = "https://dl.acm.org/doi/10.1145/3397271.3401075",
}
@inproceedings{Malkiel2020,
  author = {Malkiel, Itzik and Barkan, Oren and Caciularu, Avi and Razin, Noam and other},
  year = {2020},
  booktitle  = "Findings of the Association for Computational Linguistics: EMNLP 2020",
  month = {9},
  pages = "1704--1714",
  title = {RecoBERT: A Catalog Language Model for Text-Based Recommendations},
  url             = {https://aclanthology.org/2020.findings-emnlp.154/},
}
@misc{YanPatterns,
  author       = {Eugene Yan},
  url = {https://eugeneyan.com/writing/patterns-for-personalization/},
  title        = {Patterns for Personalization in Recommendations and Search},
  year         = {2021}
}
@article{Cui2022,
  author          = {Zeyu Cui and Jianxin Ma and Chang Zhou and Jingren Zhou and Hongxia Yang},
  journal         = {arXiv preprint arXiv:2205.08084},
  number          = {},
  title           = {M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems},
  volume          = {},
  year            = {2022},
  url             = {https://arxiv.org/abs/2205.08084}
}
@article{faiss,
  author          = {Jeff Johnson and Matthijs Douze and Herve Jegou},
  journal         = {arXiv preprint arXiv:1702.08734},
  title           = {Billion-scale similarity search with GPUs},
  year            = {2017},
  note            = {\url{https://github.com/facebookresearch/faiss}},
}
@article{MSMarco,
  author          = {Tri Nguyen and Mir Rosenberg and Xia Song and Jianfeng Gao and other},
  volume          = {MS MARCO: A Human-Generated MAchine Reading COmprehension Dataset},
  year            = {2016},
  url = {https://www.microsoft.com/en-us/research/publication/ms-marco-human-generated-machine-reading-comprehension-dataset/},
}
@article{TREC-CAR,
  author          = {Laura Dietz and Manisha Verma and Filip Radlinski and Nick Craswell},
  journal         = {Proceedings of {Text REtrieval Conference} (TREC)},
  title           = {TREC Complex Answer Retrieval Overview},
  year            = {2017},
  note            = {\url{http://trec-car.cs.unh.edu/}},
}
@article{Nogueira2019,
  author          = {Rodrigo Nogueira and Kyunghyun Cho},
  journal         = {arXiv preprint arXiv:1901.04085},
  title           = {Passage Re-ranking with BERT},
  year            = {2019},
  url             = {https://arxiv.org/abs/1901.04085},
}
@article{okhat2020,
  author = "Omar Khattab",
  title = "Question about query augmentation",
  url          = {https://github.com/stanford-futuredata/ColBERT/issues/16},
}
@article{triplepairs,
  author          = {Olivier Moindrot},
  year            = {2018},
  title      = {Triplet Loss and Online Triplet Mining in TensorFlow},
  url             = {https://omoindrot.github.io/triplet-loss},
}
@inproceedings{deSouza2018,
  author = {de Souza Pereira Moreira, Gabriel and Ferreira, Felipe and da Cunha, Adilson Marques},
  title = {News Session-Based Recommendations Using Deep Neural Networks},
  year = {2018},
  isbn = {9781450366175},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3270323.3270328},
  booktitle = {Proceedings of the 3rd Workshop on Deep Learning for Recommender Systems},
  pages = "15--23",
  series = {DLRS 2018}
}
@inproceedings{GloVe,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}
@inproceedings{word2vec,
  title={Efficient Estimation of Word Representations in Vector Space},
  author={Tomas Mikolov and Kai Chen and Gregory S. Corrado and Jeffrey Dean},
  booktitle={International Conference on Learning Representations},
  year={2013}
}
@inproceedings{Zheng2017,
  author = {Zheng, Lei and Noroozi, Vahid and Yu, Philip S.},
  title = {Joint Deep Modeling of Users and Items Using Reviews for Recommendation},
  year = {2017},
  isbn = {9781450346757},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3018661.3018665},
  doi = {10.1145/3018661.3018665},
  booktitle = {Proceedings of the Tenth ACM International Conference on Web Search and Data Mining},
  pages = "425--434",
  series = {WSDM '17}
}
@inproceedings{Djuric2015,
  author = {Djuric, Nemanja and Wu, Hao and Radosavljevic, Vladan and Grbovic, Mihajlo and Bhamidipati, Narayan},
  title = {Hierarchical Neural Language Models for Joint Representation of Streaming Documents and Their Content},
  year = {2015},
  isbn = {9781450334693},
  publisher = {International World Wide Web Conferences Steering Committee},
  address = {Republic and Canton of Geneva, CHE},
  url = {https://doi.org/10.1145/2736277.2741643},
  doi = {10.1145/2736277.2741643},
  booktitle = {Proceedings of the 24th International Conference on World Wide Web},
  pages = {248â€“255},
  series = {WWW '15}
}
@INPROCEEDINGS{FaceNet,
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={FaceNet: A unified embedding for face recognition and clustering}, 
  year={2015},
  volume={},
  number={},
  pages={815-823},
  doi={10.1109/CVPR.2015.7298682}
}
@inproceedings{Devlin2019,
  author          = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  booktitle       = {Proceedings of NAACL-HLT 2019},
  editor          = {Association for Computational Linguistics},
  title           = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year            = {2019}
}
@misc{kagglewine,
  author       = {zackthoutt@Kaggle},
  howpublished = {\url{https://www.kaggle.com/datasets/zynicide/wine-reviews}},
  title        = {Wine Reviews},
  year         = {2017}
}
@misc{expertwine,
  note="See the author's github page for this data, \url{https://github.com/r-papso/recobert}"
}
@article{M6,
  author          = {Junyang Lin and Rui Men and An Yang and Chang Zhou and others},
  journal         = {arXiv preprint arXiv:2103.00823},
  number          = {},
  title           = {M6: A Chinese Multimodal Pretrainer},
  volume          = {},
  year            = {2021}
}
@inproceedings{PromptTuning,
    title = "The Power of Scale for Parameter-Efficient Prompt Tuning",
    author = "Lester, Brian  and
      Al-Rfou, Rami  and
      Constant, Noah",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    year = "2021",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.243",
    doi = "10.18653/v1/2021.emnlp-main.243",
    pages = "3045--3059",
}
@inproceedings{Adaptation,
  author          = {Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and other},
  booktitle       = {ICLR 2022},
  editor          = {},
  title           = {LoRA: Low-Rank Adaptation of Large Language Models },
  year            = {2022}
}
@inproceedings{DIN,
  author          = {Guorui Zhou and Chengru Song and Xiaoqiang Zhu and other},
  booktitle       = {KDD 2018},
  editor          = {},
  title           = {Deep Interest Network for Click-Through Rate Prediction},
  year            = {2018}
}
@misc{StitchFixClientTime,
  title = "Client Time Series Model: a Multi-Target Recommender System based on Temporally-Masked Encoders",
  author = "Kevin Zielnicki and Dirk Sierag and Patrick Foley",
  month = "October",
  year = "2022",
  url = "https://multithreaded.stitchfix.com/blog/2022/10/14/client-time-series-model/"
  }

@inproceedings{Steed2022-upstream,
    title = "{U}pstream {M}itigation {I}s \textit{ {N}ot} {A}ll {Y}ou {N}eed: {T}esting the {B}ias {T}ransfer {H}ypothesis in {P}re-{T}rained {L}anguage {M}odels",
    author = "Steed, Ryan  and
      Panda, Swetasudha  and
      Kobren, Ari  and
      Wick, Michael",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.247",
    doi = "10.18653/v1/2022.acl-long.247",
    pages = "3524--3542",
    abstract = "A few large, homogenous, pre-trained models undergird many machine learning systems {---} and often, these models contain harmful stereotypes learned from the internet. We investigate the \textit{bias transfer hypothesis}: the theory that social biases (such as stereotypes) internalized by large language models during pre-training transfer into harmful task-specific behavior after fine-tuning. For two classification tasks, we find that reducing intrinsic bias with controlled interventions \textit{before} fine-tuning does little to mitigate the classifier{'}s discriminatory behavior \textit{after} fine-tuning. Regression analysis suggests that downstream disparities are better explained by biases in the fine-tuning dataset. Still, pre-training plays a role: simple alterations to co-occurrence rates in the fine-tuning dataset are ineffective when the model has been pre-trained. Our results encourage practitioners to focus more on dataset quality and context-specific harms.",
}
@inproceedings{GLUE,
    title = "{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    author = "Wang, Alex  and
      Singh, Amanpreet  and
      Michael, Julian  and
      Hill, Felix  and
      Levy, Omer  and
      Bowman, Samuel",
    booktitle = "Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-5446",
    doi = "10.18653/v1/W18-5446",
    pages = "353--355",
}
@inproceedings{LibraryThing,
  author          = {Tong Zhao and Julian McAuley and Irwin King},
  booktitle         = {Conference on Information and Knowledge Management (CIKM)},
  title           = {Improving Latent Factor Models via Personalized Feature
Projection for One Class Recommendation},
  year            = {2015}
}
@inproceedings{Beer,
  author          = {Julian McAuley and Jure Leskovec and Dan Jurafsky},
  booktitle       = {International Conference on Data Mining (ICDM)},
  editor          = {},
  title           = {Learning attitudes and attributes from multi-aspect reviews},
  year            = {2012}
}
@inproceedings{GoodReads,
  author    = {Mengting Wan and
               Julian J. McAuley},
  editor    = {Sole Pera and
               Michael D. Ekstrand and
               Xavier Amatriain and
               John O'Donovan},
  title     = {Item recommendation on monotonic behavior chains},
  booktitle = {Proceedings of the 12th {ACM} Conference on Recommender Systems, RecSys
               2018, Vancouver, BC, Canada, October 2-7, 2018},
  pages     = {86--94},
  publisher = {{ACM}},
  year      = {2018},
  url       = {https://doi.org/10.1145/3240323.3240369},
  doi       = {10.1145/3240323.3240369},
  timestamp = {Mon, 22 Jul 2019 19:11:02 +0200},
  biburl    = {https://dblp.org/rec/conf/recsys/WanM18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  note = "\url{https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home}"
}
@inproceedings{Transformers4Rec,
author = {de Souza Pereira Moreira, Gabriel and Rabhi, Sara and Lee, Jeong Min and Ak, Ronay and Oldridge, Even},
title = {Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation},
year = {2021},
isbn = {9781450384582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460231.3474255},
doi = {10.1145/3460231.3474255},
booktitle = {Proceedings of the 15th ACM Conference on Recommender Systems},
pages = {143â€“153},
numpages = {11},
location = {Amsterdam, Netherlands},
series = {RecSys '21},
note = "\url{https://github.com/NVIDIA-Merlin/Transformers4Rec}"
}

@inproceedings{BERT4Rec,
author = {Sun, Fei and Liu, Jun and Wu, Jian and Pei, Changhua and Lin, Xiao and Ou, Wenwu and Jiang, Peng},
title = {BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3357895},
doi = {10.1145/3357384.3357895},
abstract = {Modeling users' dynamic preferences from their historical behaviors is challenging and crucial for recommendation systems. Previous methods employ sequential neural networks to encode users' historical interactions from left to right into hidden representations for making recommendations. Despite their effectiveness, we argue that such left-to-right unidirectional models are sub-optimal due to the limitations including: begin enumerate* [label=seriesitshapealph*upshape)] item unidirectional architectures restrict the power of hidden representation in users' behavior sequences; item they often assume a rigidly ordered sequence which is not always practical. end enumerate* To address these limitations, we proposed a sequential recommendation model called BERT4Rec, which employs the deep bidirectional self-attention to model user behavior sequences. To avoid the information leakage and efficiently train the bidirectional model, we adopt the Cloze objective to sequential recommendation, predicting the random masked items in the sequence by jointly conditioning on their left and right context. In this way, we learn a bidirectional representation model to make recommendations by allowing each item in user historical behaviors to fuse information from both left and right sides. Extensive experiments on four benchmark datasets show that our model outperforms various state-of-the-art sequential models consistently.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {1441â€“1450},
numpages = {10},
keywords = {sequential recommendation, bidirectional sequential model, cloze},
location = {Beijing, China},
series = {CIKM '19}
}

@inproceedings{SAS4Rec,
author = {Kang, Wang-Cheng and McAuley, Julian},
year = {2018},
month = {11},
pages = {197-206},
title = {Self-Attentive Sequential Recommendation},
doi = {10.1109/ICDM.2018.00035}
}

@article{GRU4Rec,
author = {Hidasi, BalÃ¡zs and Karatzoglou, Alexandros and Baltrunas, Linas and Tikk, Domonkos},
year = {2015},
month = {11},
pages = {},
title = {Session-based Recommendations with Recurrent Neural Networks}
}

@article{GRU4Rec+,
author = {Hidasi, BalÃ¡zs and Karatzoglou, Alexandros},
year = {2017},
month = {06},
pages = {},
title = {Recurrent Neural Networks with Top-k Gains for Session-based Recommendations}
}


@inproceedings{SSE-PT,
author = {Wu, Liwei and Li, Shuqing and Hsieh, Cho-Jui and Sharpnack, James},
title = {SSE-PT: Sequential Recommendation Via Personalized Transformer},
year = {2020},
isbn = {9781450375832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383313.3412258},
doi = {10.1145/3383313.3412258},
abstract = {Temporal information is crucial for recommendation problems because user preferences are naturally dynamic in the real world. Recent advances in deep learning, especially the discovery of various attention mechanisms and newer architectures in addition to widely used RNN and CNN in natural language processing, have allowed for better use of the temporal ordering of items that each user has engaged with. In particular, the SASRec model, inspired by the popular Transformer model in natural languages processing, has achieved state-of-the-art results. However, SASRec, just like the original Transformer model, is inherently an un-personalized model and does not include personalized user embeddings. To overcome this limitation, we propose a Personalized Transformer (SSE-PT) model, outperforming SASRec by almost 5% in terms of NDCG@10 on 5 real-world datasets. Furthermore, after examining some random usersâ€™ engagement history, we find our model not only more interpretable but also able to focus on recent engagement patterns for each user. Moreover, our SSE-PT model with a slight modification, which we call SSE-PT++, can handle extremely long sequences and outperform SASRec in ranking results with comparable training speed, striking a balance between performance and speed requirements. Our novel application of the Stochastic Shared Embeddings (SSE) regularization is essential to the success of personalization. Code and data are open-sourced at https://github.com/wuliwei9278/SSE-PT.},
booktitle = {Proceedings of the 14th ACM Conference on Recommender Systems},
pages = {328â€“337},
numpages = {10},
keywords = {temporal collaborative ranking, recommender system, stochastic shared embeddings, neural networks, personalized transformer, sequential recommendation},
location = {Virtual Event, Brazil},
series = {RecSys '20}
}

@inproceedings{gpt2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019}
}


@inproceedings{AttentionAll,
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Attention is All you Need},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
	volume = {30},
	year = {2017},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}}


@inproceedings{FPMC,
author = {Rendle, Steffen and Freudenthaler, Christoph and Schmidt-Thieme, Lars},
title = {Factorizing Personalized Markov Chains for Next-Basket Recommendation},
year = {2010},
isbn = {9781605587998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1772690.1772773},
doi = {10.1145/1772690.1772773},
abstract = {Recommender systems are an important component of many websites. Two of the most popular approaches are based on matrix factorization (MF) and Markov chains (MC). MF methods learn the general taste of a user by factorizing the matrix over observed user-item preferences. On the other hand, MC methods model sequential behavior by learning a transition graph over items that is used to predict the next action based on the recent actions of a user. In this paper, we present a method bringing both approaches together. Our method is based on personalized transition graphs over underlying Markov chains. That means for each user an own transition matrix is learned - thus in total the method uses a transition cube. As the observations for estimating the transitions are usually very limited, our method factorizes the transition cube with a pairwise interaction model which is a special case of the Tucker Decomposition. We show that our factorized personalized MC (FPMC) model subsumes both a common Markov chain and the normal matrix factorization model. For learning the model parameters, we introduce an adaption of the Bayesian Personalized Ranking (BPR) framework for sequential basket data. Empirically, we show that our FPMC model outperforms both the common matrix factorization and the unpersonalized MC model both learned with and without factorization.},
booktitle = {Proceedings of the 19th International Conference on World Wide Web},
pages = {811â€“820},
numpages = {10},
keywords = {basket recommendation, matrix factorization, markov chain},
location = {Raleigh, North Carolina, USA},
series = {WWW '10}
}